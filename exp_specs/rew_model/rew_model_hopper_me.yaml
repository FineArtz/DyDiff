meta_data:
  script_path: run_scripts/train_reward_model.py
  exp_name: rew_model_hopper_me_v2
  description: Train the reward model
  gpu: [0]
  num_workers: 1
  using_gpus: true
# -----------------------------------------------------------------------------
variables:
  seed: [0]
    
# -----------------------------------------------------------------------------
constants:
  dataset_name: 'hopper_me_v2'
  debug: false

  model_params:
    rew_net_size: 256
    rew_num_hidden_layers: 2
    lr: 0.0001
    early_stopping_patience: 7
    holdout_ratio: 0.2
    max_holdout: 5000
    batch_size: 256
    log_freq: 5
    save_path: 'logs/reward_model'
  
  env_specs:
    env_name: 'hopper'
    env_kwargs: {}
    env_num: 4 # This parameter define how many vec envs are created
    eval_env_seed: 0 # These two seeds are no longer needed since in our implementation we makes all seeds the same, see the script file, however you can change the script to make it valid
    training_env_seed: 0
    normalize_obs: true
